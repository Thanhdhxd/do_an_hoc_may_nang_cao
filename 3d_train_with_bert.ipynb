{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3f8ade",
   "metadata": {},
   "source": [
    "## 3d.1. Kiểm Tra Môi Trường & Cài Đặt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce581dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Tắt TensorFlow logs\n",
    "warnings.filterwarnings('ignore')\n",
    "print(f'Python: {sys.version}')\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'CUDA version: {torch.version.cuda}')\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ef909",
   "metadata": {},
   "source": [
    "## 3d.2. Import Thư Viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65185450",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW  # AdamW đã chuyển sang torch.optim\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f3fb31",
   "metadata": {},
   "source": [
    "## 3d.3. Cấu Hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53d01f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config\n",
    "MODEL_NAME = 'distilbert-base-uncased'  # Nhẹ hơn bert-base-uncased 40%\n",
    "MAX_LEN = 256  # Độ dài tối đa của sequence (BERT max = 512)\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Training config\n",
    "BATCH_SIZE = 32  # Tăng lên 32 nếu GPU có nhiều RAM\n",
    "EPOCHS = 10  # Tăng lên 10 epochs với early stopping\n",
    "EARLY_STOPPING_PATIENCE = 3  # Dừng nếu 3 epochs liên tiếp không cải thiện\n",
    "LEARNING_RATE = 1e-5  # Giảm LR để training ổn định hơn (từ 2e-5 → 1e-5)\n",
    "WARMUP_RATIO = 0.1  # 10% steps đầu để warmup\n",
    "LABEL_SMOOTHING = 0.1  # Label smoothing để giảm overconfidence\n",
    "VAL_SIZE = 0.15\n",
    "SEED = 42\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = './split_augmented_data'\n",
    "TRAIN_CSV_PATH = os.path.join(DATA_DIR, 'train_augmented.csv')\n",
    "TEST_CSV_PATH = os.path.join(DATA_DIR, 'test_original.csv')\n",
    "\n",
    "OUT_DIR = './outputs_bert'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'Configuration:')\n",
    "print(f'   Model: {MODEL_NAME}')\n",
    "print(f'   Device: {device}')\n",
    "print(f'   Learning rate: {LEARNING_RATE}')\n",
    "print(f'   Label smoothing: {LABEL_SMOOTHING}')\n",
    "print(f'   Early stopping: {EARLY_STOPPING_PATIENCE} epochs patience')\n",
    "print(f'   Max length: {MAX_LEN}')\n",
    "\n",
    "print(f'   Output: {OUT_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ab329",
   "metadata": {},
   "source": [
    "## 3d.4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1987126",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading CSV data...\\n')\n",
    "\n",
    "# Load train\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "print(f'Train: {len(df_train):,} rows')\n",
    "# Load test\n",
    "df_test = pd.read_csv(TEST_CSV_PATH)\n",
    "print(f'Test: {len(df_test):,} rows')\n",
    "\n",
    "# Auto-detect columns\n",
    "text_col = df_train.columns[0]\n",
    "label_col = df_train.columns[1]\n",
    "print(f'\\nColumns: text=\"{text_col}\", label=\"{label_col}\"')\n",
    "\n",
    "# Sample\n",
    "print(f'\\nSample:')\n",
    "print(df_train.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ebfdf",
   "metadata": {},
   "source": [
    "## 3d.5. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8258d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping\n",
    "label2idx = {'negative': 0, 'positive': 1}\n",
    "idx2label = {0: 'negative', 1: 'positive'}\n",
    "\n",
    "# Extract\n",
    "train_texts = df_train[text_col].astype(str).tolist()\n",
    "train_labels = df_train[label_col].map(label2idx).values\n",
    "\n",
    "test_texts = df_test[text_col].astype(str).tolist()\n",
    "test_labels = df_test[label_col].map(label2idx).values\n",
    "\n",
    "print(f'Extracted:')\n",
    "print(f'   Train: {len(train_texts):,} samples')\n",
    "print(f'   Test: {len(test_texts):,} samples')\n",
    "\n",
    "# Distribution\n",
    "print(f'\\nLabel distribution:')\n",
    "for label, count in sorted(Counter(train_labels).items()):\n",
    "    print(f'   Train {idx2label[label]}: {count:,} ({count/len(train_labels)*100:.1f}%)')\n",
    "for label, count in sorted(Counter(test_labels).items()):\n",
    "    print(f'   Test {idx2label[label]}: {count:,} ({count/len(test_labels)*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3e852e",
   "metadata": {},
   "source": [
    "## 3d.6. Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce164641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Splitting train/val ({100*(1-VAL_SIZE):.0f}%/{100*VAL_SIZE:.0f}%)...\\n')\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_texts, train_labels,\n",
    "    test_size=VAL_SIZE,\n",
    "    random_state=SEED,\n",
    "    stratify=train_labels\n",
    ")\n",
    "\n",
    "print(f'Split:')\n",
    "print(f'   Train: {len(X_train):,}')\n",
    "print(f'   Val: {len(X_val):,}')\n",
    "print(f'   Test: {len(test_texts):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d203b",
   "metadata": {},
   "source": [
    "## 3d.7. Load Tokenizer & Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee438e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Loading tokenizer: {MODEL_NAME}\\n')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print('Tokenizer loaded')\n",
    "print(f'   Vocab size: {tokenizer.vocab_size:,}')\n",
    "print(f'   Max model length: {tokenizer.model_max_length:,}')\n",
    "\n",
    "# Test tokenize\n",
    "sample = X_train[0][:100]\n",
    "encoded = tokenizer(sample, truncation=True, max_length=MAX_LEN)\n",
    "print(f'\\nSample encoding:')\n",
    "print(f'   Text: \"{sample}\"')\n",
    "print(f'   Tokens: {len(encoded[\"input_ids\"])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd7af4f",
   "metadata": {},
   "source": [
    "## 3d.8. Create Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76e0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(' Dataset class defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbe5516",
   "metadata": {},
   "source": [
    "## 3d.9. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11adb51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating datasets and dataloaders...\\n')\n",
    "\n",
    "train_dataset = SentimentDataset(X_train, y_train, tokenizer, MAX_LEN)\n",
    "val_dataset = SentimentDataset(X_val, y_val, tokenizer, MAX_LEN)\n",
    "test_dataset = SentimentDataset(test_texts, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print('DataLoaders created:')\n",
    "print(f'   Train batches: {len(train_loader)}')\n",
    "print(f'   Val batches: {len(val_loader)}')\n",
    "print(f'   Test batches: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49714c7",
   "metadata": {},
   "source": [
    "## 3d.10. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5395f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Loading model: {MODEL_NAME}\\n')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=NUM_CLASSES,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print('Model loaded:')\n",
    "print(f'   Total parameters: {sum(p.numel() for p in model.parameters()):,}')\n",
    "print(f'   Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
    "print(f'   Device: {next(model.parameters()).device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db210ddc",
   "metadata": {},
   "source": [
    "## 3d.11. Setup Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# Scheduler với warmup\n",
    "total_steps = len(train_loader) * EPOCHS\n",
    "warmup_steps = int(total_steps * WARMUP_RATIO)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "print('Optimizer & Scheduler:')\n",
    "print(f'   Learning rate: {LEARNING_RATE}')\n",
    "print(f'   Total steps: {total_steps:,}')\n",
    "print(f'   Warmup steps: {warmup_steps:,} ({WARMUP_RATIO*100:.0f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bb4e3c",
   "metadata": {},
   "source": [
    "## 3d.12. Training & Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cb741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    # Loss function với label smoothing\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "    \n",
    "    for batch in tqdm(data_loader, desc='Training'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Không dùng labels trong model để tự tính loss với label smoothing\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # Tính loss với label smoothing\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc='Evaluating'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "    print('Training functions defined')\n",
    "\n",
    "    return np.mean(losses), acc, f1, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477470c",
   "metadata": {},
   "source": [
    "## 3d.13. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef015559",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('TRAINING STARTED')\n",
    "print('='*80)\n",
    "print(f'Model: {MODEL_NAME}')\n",
    "print(f'Train samples: {len(train_dataset):,}')\n",
    "print(f'Val samples: {len(val_dataset):,}')\n",
    "print(f'Epochs: {EPOCHS}')\n",
    "print(f'Early Stopping: Patience = {EARLY_STOPPING_PATIENCE} epochs')\n",
    "print('='*80 + '\\n')\n",
    "\n",
    "best_val_f1 = 0\n",
    "best_epoch = 0\n",
    "epochs_without_improvement = 0\n",
    "history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'\\nEpoch {epoch+1}/{EPOCHS}')\n",
    "    print('-' * 60)\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_f1, _, _ = eval_model(model, val_loader, device)\n",
    "    \n",
    "    history.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc,\n",
    "        'val_f1': val_f1\n",
    "    })\n",
    "    \n",
    "    print(f'\\nResults:')\n",
    "    print(f'   Train Loss: {train_loss:.4f}')\n",
    "    print(f'   Val Loss: {val_loss:.4f}')\n",
    "    print(f'   Val Acc: {val_acc:.4f}')\n",
    "    print(f'   Val F1: {val_f1:.4f}')\n",
    "    \n",
    "    # Check improvement\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        best_epoch = epoch + 1\n",
    "        epochs_without_improvement = 0\n",
    "        \n",
    "        model_save_path = os.path.join(OUT_DIR, 'best_model')\n",
    "        model.save_pretrained(model_save_path)\n",
    "        tokenizer.save_pretrained(model_save_path)\n",
    "        print(f'   Saved best model (F1: {best_val_f1:.4f})')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f'   No improvement ({epochs_without_improvement}/{EARLY_STOPPING_PATIENCE})')\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= EARLY_STOPPING_PATIENCE:\n",
    "        print(f'\\nEarly stopping triggered!')\n",
    "        print(f'   No improvement for {EARLY_STOPPING_PATIENCE} consecutive epochs')\n",
    "        print(f'   Best Val F1: {best_val_f1:.4f} (Epoch {best_epoch})')\n",
    "        break\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "if epochs_without_improvement >= EARLY_STOPPING_PATIENCE:\n",
    "    print(f'TRAINING STOPPED EARLY (Epoch {epoch+1}/{EPOCHS})')\n",
    "else:\n",
    "    print('TRAINING COMPLETED!')\n",
    "print(f'Best model from Epoch {best_epoch} with Val F1: {best_val_f1:.4f}')\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb76b0e",
   "metadata": {},
   "source": [
    "## 3d.14. Load Best Model & Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nLoading best model...\\n')\n",
    "\n",
    "model_save_path = os.path.join(OUT_DIR, 'best_model')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_save_path)\n",
    "model = model.to(device)\n",
    "\n",
    "print('Best model loaded')\n",
    "\n",
    "# Evaluate on test set\n",
    "print('\\n' + '='*80)\n",
    "print('TEST SET EVALUATION (KHÔNG AUGMENT - KHÁCH QUAN)')\n",
    "print('='*80)\n",
    "\n",
    "test_loss, test_acc, test_f1, test_preds, test_true = eval_model(model, test_loader, device)\n",
    "\n",
    "print(f'\\nTest Performance:')\n",
    "print(f'   Loss: {test_loss:.4f}')\n",
    "print(f'   Accuracy: {test_acc:.4f}')\n",
    "print(f'   Macro F1: {test_f1:.4f}')\n",
    "\n",
    "print(f'\\nClassification Report:')\n",
    "print(classification_report(test_true, test_preds, target_names=['negative', 'positive']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_true, test_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['negative', 'positive'],\n",
    "            yticklabels=['negative', 'positive'])\n",
    "plt.title(f'Confusion Matrix - Test Set (BERT)\\nF1: {test_f1:.4f}', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, 'test_confusion_matrix.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef7209",
   "metadata": {},
   "source": [
    "## 3d.15. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert history to DataFrame\n",
    "df_history = pd.DataFrame(history)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(df_history['epoch'], df_history['train_loss'], marker='o', label='Train Loss', linewidth=2)\n",
    "axes[0].plot(df_history['epoch'], df_history['val_loss'], marker='s', label='Val Loss', linewidth=2)\n",
    "axes[0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# F1\n",
    "axes[1].plot(df_history['epoch'], df_history['val_f1'], marker='o', color='orange', linewidth=2, label='Val F1')\n",
    "axes[1].axhline(y=best_val_f1, color='r', linestyle='--', label=f'Best Val F1: {best_val_f1:.4f}')\n",
    "axes[1].axhline(y=test_f1, color='g', linestyle='--', label=f'Test F1: {test_f1:.4f}')\n",
    "axes[1].set_title('Validation F1 Score', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('F1 Score', fontsize=12)\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, 'training_history.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('Training history saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e6189d",
   "metadata": {},
   "source": [
    "## 3d.16. Save Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f20c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'model_type': 'DistilBERT',\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'max_length': MAX_LEN,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'epochs': EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'warmup_ratio': WARMUP_RATIO,\n",
    "    'best_val_f1': float(best_val_f1),\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'test_f1': float(test_f1),\n",
    "    'train_samples': len(train_dataset),\n",
    "    'val_samples': len(val_dataset),\n",
    "    'test_samples': len(test_dataset),\n",
    "    'train_augmented': True,\n",
    "    'test_augmented': False,\n",
    "    'data_source': 'CSV (split_augmented_data)',\n",
    "    'device': str(device)\n",
    "}\n",
    "\n",
    "meta_path = os.path.join(OUT_DIR, 'meta.json')\n",
    "with open(meta_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print('Metadata saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e45f81",
   "metadata": {},
   "source": [
    "## 3d.17. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf7ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('BERT TRAINING COMPLETED!')\n",
    "print('='*80)\n",
    "\n",
    "print(f'\\nConfiguration:')\n",
    "print(f'   Model: {MODEL_NAME}')\n",
    "print(f'   Max length: {MAX_LEN}')\n",
    "print(f'   Batch size: {BATCH_SIZE}')\n",
    "print(f'   Epochs: {EPOCHS}')\n",
    "print(f'   Learning rate: {LEARNING_RATE}')\n",
    "\n",
    "print(f'\\nPerformance:')\n",
    "print(f'   Best Val F1: {best_val_f1:.4f}')\n",
    "print(f'   Test Accuracy: {test_acc:.4f}')\n",
    "print(f'   Test F1: {test_f1:.4f}')\n",
    "\n",
    "print(f'\\nSaved files in {OUT_DIR}:')\n",
    "for item in sorted(os.listdir(OUT_DIR)):\n",
    "    item_path = os.path.join(OUT_DIR, item)\n",
    "    if os.path.isfile(item_path):\n",
    "        size_kb = os.path.getsize(item_path) / 1024\n",
    "        print(f'   - {item:30s} ({size_kb:>8.1f} KB)')\n",
    "    elif os.path.isdir(item_path):\n",
    "        print(f'   - {item}/ (directory)')\n",
    "\n",
    "print('\\n' + '='*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
